{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u_vnEQxwnB7D"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "from fcmeans import FCM\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import os\n",
    "import pyedflib\n",
    "import pywt\n",
    "import random\n",
    "import re\n",
    "import scipy.stats\n",
    "from scipy.stats import entropy, tstd, tmean\n",
    "from scipy import signal\n",
    "import sklearn.cluster\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q1qM0r4amauX"
   },
   "outputs": [],
   "source": [
    "def under_sample(data):\n",
    "  normal_index = data[:,1] == 0\n",
    "  abnormal_index = data[:,1] == 1\n",
    "\n",
    "  normal = data[normal_index, :]\n",
    "  abnormal = data[abnormal_index, :]\n",
    "\n",
    "  rand_index = np.random.choice(normal.shape[0], abnormal.shape[0], replace=False)\n",
    "  normal_sample = normal[rand_index, :]\n",
    "\n",
    "  dataset = np.concatenate((abnormal, normal_sample))\n",
    "  np.random.shuffle(dataset)\n",
    "\n",
    "  return np.asarray([x for x in dataset[:,0]]), np.asarray(dataset)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "omd80nIcBT-k"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Helper functions to compute the features\n",
    "################################################################################\n",
    "\n",
    "def calculate_ave_power(coeffs):\n",
    "    ave_power = np.sum(np.square(coeffs)) / len(coeffs)\n",
    "    return ave_power\n",
    "\n",
    "def calculate_mean(coeffs):\n",
    "    mean = scipy.stats.tmean(coeffs)\n",
    "    return mean\n",
    "\n",
    "def calculate_entropy(coeffs):\n",
    "    counter = Counter(coeffs).most_common()\n",
    "    pk = [x[1] / len(coeffs) for x in counter]\n",
    "    entropy = scipy.stats.entropy(pk)\n",
    "    return entropy\n",
    "\n",
    "def calculate_std_dev(coeffs):\n",
    "    std_dev = scipy.stats.tstd(coeffs)\n",
    "    return std_dev\n",
    "\n",
    "def get_features(coeffs):\n",
    "    ave_power = calculate_ave_power(coeffs)\n",
    "    mean = calculate_mean(coeffs)\n",
    "    std_dev = calculate_std_dev(coeffs)\n",
    "    entropy = calculate_entropy(np.asarray(coeffs))\n",
    "\n",
    "    return [ave_power, mean, std_dev, entropy]\n",
    "\n",
    "################################################################################\n",
    "# Perform multi-level 1D Discrete Wavelet Transform (DWT)\n",
    "# Approximation and coefficients of the previous level is the input to the\n",
    "# current level\n",
    "################################################################################\n",
    "\n",
    "def get_dwt_features(signal):\n",
    "    coeffs = pywt.wavedec(signal, 'db2', level=2)\n",
    "    return get_features(np.concatenate(coeffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB6cE0M42rWA"
   },
   "source": [
    "# Validation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "k5DpbGRhV_Fb"
   },
   "outputs": [],
   "source": [
    "def is_abnormal(index, seg_size, durations):\n",
    "  for duration in durations:\n",
    "    seizure_start = duration[0]\n",
    "    seizure_end = duration[1]\n",
    "    seg_start = index\n",
    "    seg_end = index + seg_size\n",
    "\n",
    "    if seizure_start <= seg_start <= seizure_end or seg_start <= seizure_start <= seg_end:\n",
    "      return True\n",
    "\n",
    "  return False\n",
    "\n",
    "def segment(signal):\n",
    "    seg_size = 1280 # 5 Seconds\n",
    "    overlap = 0.1 # 90% overlap\n",
    "    index = 0\n",
    "    segments = []\n",
    "\n",
    "    need_last_seg = True\n",
    "\n",
    "    while index <= len(signal) - 1280:\n",
    "      if index + seg_size == len(signal) - 1:\n",
    "        need_last_seg = False\n",
    "\n",
    "      segment = signal[index:index + seg_size]\n",
    "      features = get_dwt_features(segment)\n",
    "      segments.append(features)\n",
    "      \n",
    "      index += math.ceil(overlap * seg_size)\n",
    "\n",
    "    if need_last_seg:\n",
    "      segment = signal[-seg_size:]\n",
    "      segments.append(get_dwt_features(segment))\n",
    "\n",
    "    return np.asarray(segments)\n",
    "\n",
    "def load_single_file(edf_file):\n",
    "  X_data = []\n",
    "  f = pyedflib.EdfReader(edf_file)\n",
    "  n = f.signals_in_file\n",
    "  for i in range(n):\n",
    "    signal = f.readSignal(i, digital=True)\n",
    "    segments = segment(signal)\n",
    "    X_data.append(segments)\n",
    "  f.close()\n",
    "  return np.asarray(X_data)\n",
    "\n",
    "def calculate_seziure_times(labels, tolerance=1):\n",
    "  start = None\n",
    "  count = 0\n",
    "  seizures = []\n",
    "  for (index, label) in enumerate(labels):\n",
    "    if label:\n",
    "      if not start:\n",
    "        start = index * 128\n",
    "    else:\n",
    "      if start:\n",
    "        count += 1\n",
    "        if count == tolerance:\n",
    "          seizures.append((start, index * 128))\n",
    "          start = None\n",
    "          count = 0\n",
    "  return seizures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1TN8jceKwPPM"
   },
   "outputs": [],
   "source": [
    "def test_cmeans(edf_file):\n",
    "  warnings.filterwarnings('ignore')\n",
    "  #dataset = json.load(open(r'C:\\Users\\kscot\\Documents\\TestResults\\CHB01\\Dataset_CHB01.json'))\n",
    "  dataset = json.load(open(r'/Users/fatimasiddiqui/Documents/School/Sem1/ECE496/Dataset_CHB01.json'))\n",
    "\n",
    "  train_set = dataset[:2] + dataset[3:]\n",
    "  X_train = [i[1] for i in train_set]\n",
    "  X_train = [j for i in X_train for j in i]\n",
    "\n",
    "  Y_train = [i[2] for i in train_set]\n",
    "  Y_train = [j for i in Y_train for j in i]\n",
    "\n",
    "  X_train, Y_train = under_sample(np.array(list(zip(X_train, Y_train))))\n",
    "  \n",
    "  ideal_k = 4\n",
    "  cmeans = FCM(n_clusters=ideal_k)\n",
    "  cmeans.fit(X_train)\n",
    "\n",
    "  cluster_assignments = cmeans.predict(X_train)\n",
    "  contingency_matrix = metrics.cluster.contingency_matrix(Y_train, cluster_assignments)\n",
    "\n",
    "  label_mapping = np.argmax(contingency_matrix, axis=0)\n",
    "\n",
    "  ################################################################################\n",
    "  # Start Timer\n",
    "  start_time = time.time()\n",
    "\n",
    "  X_test = load_single_file(edf_file)\n",
    "  all_seizure_times = []\n",
    "  ret = \"\"\n",
    "  \n",
    "  all_seizure_start_times = []\n",
    "  #test_f = open(r\"C:\\Users\\kscot\\Documents\\chb-mit-scalp-eeg-database-1.0.0\\out.csv\", \"a\")\n",
    "  test_f = open(r\"/Users/fatimasiddiqui/Documents/School/Sem1/ECE496/results/out.csv\", \"a\")\n",
    "\n",
    "  for index, signal in enumerate(X_test):\n",
    "    ret += \"Channel \" + str (index + 1) + \": \"\n",
    "    predictions = cmeans.predict(signal)\n",
    "    labels = [label_mapping[i] for i in predictions]\n",
    "\n",
    "    seizure_times = calculate_seziure_times(labels)\n",
    "    seizure_start_times = \"Ch\" + str(index + 1)\n",
    "\n",
    "    for seizure_time in seizure_times:\n",
    "      ret += \"Start: \" + str(seizure_time[0]) + \", End: \" + str(seizure_time[1]) + \"; \"\n",
    "      seizure_start_times += \",\" + str(seizure_time[0])\n",
    "\n",
    "    seizure_start_times += \"\\n\"\n",
    "    test_f.write(seizure_start_times)\n",
    "    ret += \"\\n\\n\"\n",
    "\n",
    "  test_f.close()\n",
    "\n",
    "  # End Timer\n",
    "  end_time = time.time()\n",
    "  elapsed_time = end_time - start_time\n",
    "  ################################################################################\n",
    "\n",
    "  ret += \"\\n\\nElapsed Time: \" + str(elapsed_time)\n",
    "  print(all_seizure_start_times)\n",
    "\n",
    "  #test_f = open(r\"C:\\Users\\kscot\\Documents\\chb-mit-scalp-eeg-database-1.0.0\\out.txt\", \"w\")\n",
    "  test_f = open(r\"/Users/fatimasiddiqui/Documents/School/Sem1/ECE496/results/out.txt\", \"w\")\n",
    "  test_f.write(ret)\n",
    "  test_f.close()\n",
    "\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqgKVWvMB8Qp",
    "outputId": "740ce074-7fe0-4eb8-f8f8-07a800045d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Python program to create\n",
    "# a file explorer in Tkinter\n",
    "  \n",
    "# import all components\n",
    "# from the tkinter library\n",
    "from tkinter import *\n",
    "  \n",
    "# import filedialog module\n",
    "from tkinter import filedialog\n",
    "  \n",
    "# Function for opening the\n",
    "# file explorer window\n",
    "\n",
    "def browseFiles():\n",
    "    filename = filedialog.askopenfilename(initialdir = \"/\",\n",
    "                                          title = \"Select a File\",\n",
    "                                          filetypes = ((\"EDF Files\",\n",
    "                                                        \"*.edf\"),\n",
    "                                                       (\"all files\",\n",
    "                                                        \"*.*\")))\n",
    "    \n",
    "    if filename:\n",
    "      label_file_explorer.configure(text=\"Loading...\")\n",
    "      out = test_cmeans(filename)\n",
    "      # Change label contents\n",
    "      #label_file_explorer.configure(text=\"File Opened: \"+filename)\n",
    "      label_file_explorer.configure(text=out)\n",
    "    \n",
    "      \n",
    "                                                                                                  \n",
    "# Create the root window\n",
    "window = Tk()\n",
    "  \n",
    "# Set window title\n",
    "window.title('Seizure Detection')\n",
    "  \n",
    "# Set window size\n",
    "#window.geometry(\"520x520\")\n",
    "  \n",
    "#Set window background color\n",
    "window.config(background = \"white\")\n",
    "  \n",
    "# Create a File Explorer label\n",
    "label_file_explorer = Label(window,\n",
    "                            text = \"Select an EDF File\",\n",
    "                            width = 60, height = 27,\n",
    "                            fg = \"blue\")\n",
    "  \n",
    "      \n",
    "button_explore = Button(window,\n",
    "                        text = \"Browse Files\",\n",
    "                        command = browseFiles)\n",
    "  \n",
    "# Grid method is chosen for placing\n",
    "# the widgets at respective positions\n",
    "# in a table like structure by\n",
    "# specifying rows and columns\n",
    "label_file_explorer.grid(column = 1, row = 1)\n",
    "  \n",
    "button_explore.grid(column = 1, row = 2)\n",
    "  \n",
    "# Let the window wait for any events\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
