{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KqTI79yGl0g_C2-L-JwUySfuIjP7EEcI","timestamp":1679774787461},{"file_id":"1cT8xKOIqIeDByrak41uOio8CbLY5eaAW","timestamp":1675292847021},{"file_id":"112CHiC2F9HoRlbaEyutnnE37B1MteBtv","timestamp":1672433897602},{"file_id":"1i4D54vOMp5n_R0vsV76Wo_HroAT5xS9H","timestamp":1669843420589},{"file_id":"1Pou_AJwNzoh6bmW3E2E8Tsw9g0P02n_G","timestamp":1669490938106}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Clustering"],"metadata":{"id":"7twu2kYQETYP"}},{"cell_type":"code","source":["import collections\n","from collections import Counter\n","from fcmeans import FCM\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pickle\n","import pyedflib\n","import pynwb\n","from pynwb import NWBFile\n","from pynwb import TimeSeries\n","import pywt\n","import random\n","import re\n","import scipy.stats\n","from scipy.stats import entropy, tstd, tmean\n","from scipy import signal\n","import sklearn.cluster\n","from sklearn.cluster import Birch\n","from sklearn.cluster import KMeans\n","from sklearn import metrics\n","from tabulate import tabulate\n","import warnings"],"metadata":{"id":"u_vnEQxwnB7D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Convert Data"],"metadata":{"id":"LYXy7pJ1Ebdg"}},{"cell_type":"markdown","source":["Download the dataset"],"metadata":{"id":"T76XW9_2lmIJ"}},{"cell_type":"code","source":["dataset_root = r\"\" # Path to patient EDF files\n","summary_path = r\"\" # Path to patient summary.txt file\n","\n","def get_dataset_stats():\n","  dataset_stats = []\n","\n","  summary_text = open(summary_path, \"r\").read()\n","  parsed_summary = re.split(\"\\n\\n\", summary_text)[2:]\n","  seizure_numbers = re.findall(r'Number of Seizures in File: (.)', summary_text)\n","  max_seizures_file = max([int(x) for x in seizure_numbers])\n","\n","  for summary in parsed_summary:\n","    file_name = re.search(r'File Name: (.*?)\\n', summary)\n","    if file_name:\n","      file_name = file_name.group(1)\n","      seizure_durations = []\n","\n","      num_seizures = re.search(r'Number of Seizures in File: (.)', summary).group(1)\n","      num_seizures =  int(num_seizures)\n","      \n","      if(num_seizures > 0):\n","        if max_seizures_file < 2:\n","          seizure_start_time = re.search(r'Seizure Start Time: (.*?) seconds\\n', summary)\n","          seizure_end_time = re.search('Seizure End Time: (.*?) seconds', summary)\n","          if seizure_start_time:\n","            seizure_start_time = int(seizure_start_time.group(1)) * 256\n","            seizure_end_time = int(seizure_end_time.group(1)) * 256\n","            seizure_durations.append((seizure_start_time, seizure_end_time))\n","          else:\n","            seizure_start_time = int(re.search(r'Seizure 1 Start Time: (.*?) seconds\\n', summary).group(1)) * 256\n","            seizure_end_time = int(re.search('Seizure 1 End Time: (.*?) seconds', summary).group(1)) * 256\n","            seizure_durations.append((seizure_start_time, seizure_end_time))\n","        else:\n","          for i in range(num_seizures):\n","            seizure_num = i + 1\n","            seizure_start_time = re.search(r'Seizure %i Start Time: (.*?) seconds\\n'%(seizure_num), summary)\n","            seizure_end_time = re.search('Seizure %i End Time: (.*?) seconds'%(seizure_num), summary)\n","            if seizure_start_time:\n","              seizure_start_time = int(seizure_start_time.group(1)) * 256\n","              seizure_end_time = int(seizure_end_time.group(1)) * 256\n","              seizure_durations.append((seizure_start_time, seizure_end_time))\n","            else:\n","              seizure_start_time = int(re.search(r'Seizure Start Time: (.*?) seconds\\n', summary).group(1)) * 256\n","              seizure_end_time = int(re.search('Seizure End Time: (.*?) seconds', summary).group(1)) * 256\n","              seizure_durations.append((seizure_start_time, seizure_end_time))\n","      dataset_stats.append([file_name, num_seizures, seizure_durations])\n","  return np.asarray(dataset_stats)\n","\n","dataset_stats = get_dataset_stats()"],"metadata":{"id":"nQkiA-J7f2pA","executionInfo":{"status":"ok","timestamp":1677535684744,"user_tz":300,"elapsed":16,"user":{"displayName":"Khalil “Anthony” Scott","userId":"12781794652735440753"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f282f03c-0095-4c7a-ec99-2ca0ffb09131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-fa2d1a47cc90>:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return np.asarray(dataset_stats)\n"]}]},{"cell_type":"code","source":["def is_abnormal(index, seg_size, durations):\n","  for duration in durations:\n","    seizure_start = duration[0]\n","    seizure_end = duration[1]\n","    seg_start = index\n","    seg_end = index + seg_size\n","\n","    if seizure_start <= seg_start <= seizure_end or seg_start <= seizure_start <= seg_end:\n","      return True\n","\n","  return False\n","\n","def segment(signal, durations):\n","    seg_size = 1280 # 5 Seconds\n","    overlap = 0.1 # 90% overlap\n","    index = 0\n","    segments = []\n","    labels = []\n","\n","    need_last_seg = True\n","\n","    while index <= len(signal) - 1280:\n","      if index + seg_size == len(signal) - 1:\n","        need_last_seg = False\n","\n","      segment = signal[index:index + seg_size]\n","      features = get_dwt_features(segment)\n","      segments.append(features)\n","      \n","      # Add labels for each segment\n","        # 0 - Normal\n","        # 1 - Abnormal\n","      if is_abnormal(index, seg_size, durations):\n","        labels.append(1)\n","      else:\n","        labels.append(0)\n","\n","      index += math.ceil(overlap * seg_size)\n","\n","    if need_last_seg:\n","      segment = signal[-seg_size:]\n","      segments.append(get_dwt_features(segment))\n","      \n","      if is_abnormal(len(signal) - 1 - seg_size, seg_size, durations):\n","        labels.append(1)\n","      else:\n","        labels.append(0)\n","\n","    return segments, labels\n","\n","def load_data(stats, func):\n","  file_names = stats[:,0]\n","  dataset = []\n","  seg_size = 1280\n","\n","  for root, dir, files in os.walk(dataset_root, topdown=False):\n","    for name in files:\n","      if name in file_names:\n","        X_data = []\n","        Y_data = []\n","        index = np.where(file_names == name)[0][0]\n","        f = pyedflib.EdfReader(os.path.join(root, name))\n","        n = f.signals_in_file\n","        for i in range(n):\n","          signal = f.readSignal(i, digital=True)\n","          segments, labels = segment(signal, stats[index][2])\n","          X_data += segments\n","          Y_data += labels\n","        f.close()\n","        dataset.append((name, X_data, Y_data, stats[index][2]))\n","  return dataset\n","\n","dataset = load_data(dataset_stats, get_dwt_features)"],"metadata":{"id":"0_QY0-PFumRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def under_sample(data):\n","  normal_index = data[:,1] == 0\n","  abnormal_index = data[:,1] == 1\n","\n","  normal = data[normal_index, :]\n","  abnormal = data[abnormal_index, :]\n","\n","  rand_index = np.random.choice(normal.shape[0], abnormal.shape[0], replace=False)\n","  normal_sample = normal[rand_index, :]\n","\n","  dataset = np.concatenate((abnormal, normal_sample))\n","  np.random.shuffle(dataset)\n","\n","  return np.asarray([x for x in dataset[:,0]]), np.asarray(dataset)[:,1]"],"metadata":{"id":"q1qM0r4amauX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Validation Methods"],"metadata":{"id":"fB6cE0M42rWA"}},{"cell_type":"code","source":["def get_overlap(start_1, end_1, start_2, end_2):\n","  return range(max(start_1, start_2), min(end_1, end_2))\n","\n","def is_overlaping(start_1, end_1, start_2, end_2):\n","  if len(get_overlap(start_1, end_1, start_2, end_2)):\n","    return True\n","  return False\n","\n","def calculate_seziure_times(labels, tolerance=5):\n","  start = None\n","  count = 0\n","  seizures = []\n","  for (index, label) in enumerate(labels):\n","    if label:\n","      if not start:\n","        start = index * 128\n","    else:\n","      if start:\n","        count += 1\n","        if count == tolerance:\n","          seizures.append((start, index * 128))\n","          start = None\n","          count = 0\n","  return seizures\n","\n","def calculate_latency(seizure_durations, seizure_times):\n","  count = 0\n","  S = len(seizure_durations)\n","  latency = 0\n","\n","  if S == 0:\n","    return -1\n","\n","  for (seizure_start, seizure_end) in seizure_durations:\n","    for (start, end) in seizure_times:\n","      overlap = get_overlap(seizure_start, seizure_end, start, end)\n","      if len(overlap):\n","        latency += (overlap[0] - seizure_start) / 256\n","        count += 1\n","        break\n","\n","  if count == 0:\n","    return -1\n","\n","  return latency / count\n","\n","def calculate_sensitivity(seizure_durations, seizure_times):\n","  count = 0\n","  S = len(seizure_durations)\n","\n","  if S == 0:\n","    return -1\n","  \n","  for (seizure_start, seizure_end) in seizure_durations:\n","    detected = False\n","    for (start, end) in seizure_times:\n","      if is_overlaping(seizure_start, seizure_end, start, end):\n","        count += 1\n","        break\n","  return count / S\n","\n","def calculate_false_pos_rate(Y_test, Y_pred):\n","  count = 0\n","  N = len([label for label in Y_test if label == 0])\n","\n","  for i in range(len(Y_pred)):\n","    if Y_pred[i] and not Y_test[i]:\n","      count += 1\n","\n","  return 3600 * 256 * (count / N)\n","\n","def calculate_false_neg_rate(Y_test, Y_pred):\n","  count = 0\n","  N = len"],"metadata":{"id":"_2zYhX7pqBRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, X_train, Y_train, X_test, Y_test, seizure_durations, cluster_assignments, ictal):\n","  # Training\n","  contingency_matrix = metrics.cluster.contingency_matrix(Y_train, cluster_assignments)\n","  label_mapping = np.argmax(contingency_matrix, axis=0)\n","  \n","  #Testing\n","  predictions = model.predict(X_test)\n","  labels = [label_mapping[i] for i in predictions]\n","  seizure_times = calculate_seziure_times(labels)\n","\n","  latency = -1\n","  sensitivity = -1\n","\n","  # Evaluation Metrics\n","  if ictal:\n","    latency = calculate_latency(seizure_durations, seizure_times)\n","    sensitivity = calculate_sensitivity(seizure_durations, seizure_times)\n","  false_pos_rate = calculate_false_pos_rate(Y_test, labels)\n","\n","  return latency, sensitivity, false_pos_rate"],"metadata":{"id":"Zf2kw9lEdzUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_train_test_set(index, test_set, dataset):\n","  X_test = np.asarray(test_set[1])\n","  Y_test = test_set[2]\n","  seizure_durations = test_set[3]\n","  \n","  train_set = dataset[:index] + dataset[index + 1:]\n","\n","  X_train = [i[1] for i in train_set]\n","  X_train = [j for i in X_train for j in i]\n","\n","  Y_train = [i[2] for i in train_set]\n","  Y_train = [j for i in Y_train for j in i]\n","\n","  X_train, Y_train = under_sample(np.array(list(zip(X_train, Y_train))))\n","\n","  return X_train, Y_train, X_test, Y_test, seizure_durations\n","\n","def evaluate_model_test(model, cmeans=False):\n","  fpr_iterictal = 0\n","  fpr_ictal = 0\n","  avg_latency = 0\n","  avg_sensitivity = 0\n","\n","  count_ictal = 0\n","  count_iterictal = 0\n","\n","  for index, test_set in enumerate(dataset):\n","    patient_file = (test_set[0][:-4])\n","    X_train, Y_train, X_test, Y_test, seizure_durations = get_train_test_set(index, test_set, dataset)\n","\n","    ictal = len(seizure_durations) > 0\n","\n","    # Train and test Model 1\n","    model.fit(X_train)\n","    cluster_assignments = 0\n","    \n","    if cmeans:\n","      cluster_assignments = model.predict(X_train)\n","    else:\n","      cluster_assignments = model.labels_\n","      \n","    latency, sensitivity, false_pos_rate = evaluate(model, X_train, Y_train, X_test, Y_test, seizure_durations, cluster_assignments, ictal)\n","\n","    if ictal:\n","      count_ictal += 1\n","      avg_latency += max(0, latency)\n","      avg_sensitivity += max(0, sensitivity)\n","      fpr_ictal += false_pos_rate\n","    else:\n","      count_iterictal += 1\n","      fpr_iterictal += false_pos_rate\n","\n","  if not count_ictal == 0:\n","    avg_latency /= count_ictal\n","    avg_sensitivity /= count_ictal\n","    fpr_ictal /= count_ictal\n","\n","  if not count_iterictal == 0:\n","    fpr_iterictal /= count_iterictal\n","\n","  print(tabulate([[avg_latency, avg_sensitivity, fpr_ictal, fpr_iterictal]], headers=[\"Latency\", \"Sensitivity\", \"False Positive Rate (Ictal)\", \"False Positive Rate (Interictal)\"], tablefmt=\"pretty\"))"],"metadata":{"id":"4lDZw6k38ooS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing BIRCH"],"metadata":{"id":"m_3lw6JS7pOe"}},{"cell_type":"code","source":["warnings.filterwarnings('ignore')\n","\n","ideal_k_birch = 2\n","birch = Birch(threshold=10, branching_factor=80, n_clusters=ideal_k_birch, compute_labels=True, copy=True)\n","evaluate_model_test(birch)"],"metadata":{"id":"_ZSeRxJ44ktE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing Kmeans"],"metadata":{"id":"kWbeqeU08j2P"}},{"cell_type":"code","source":["ideal_k_kmeans = 4\n","kmeans = KMeans(n_clusters=ideal_k_kmeans)\n","evaluate_model_test(kmeans)"],"metadata":{"id":"p62LVKW58qRt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing Fuzzy C-Means"],"metadata":{"id":"iOSLmARt8meG"}},{"cell_type":"code","source":["ideal_k_cmeans = 4\n","cmeans = FCM(n_clusters=ideal_k_cmeans)\n","evaluate_model_test(cmeans, True)"],"metadata":{"id":"2z2yncSb8rDJ"},"execution_count":null,"outputs":[]}]}